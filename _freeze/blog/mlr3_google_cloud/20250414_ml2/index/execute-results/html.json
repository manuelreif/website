{
  "hash": "dc81c3e8fda3e882a6d2006a91e1087b",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Machine Learning in der Google Cloud 2\"\ndescription: \"Datenpipelines sind der coolste Part an einem Machine Learning Projekt. Warum? Man kann in einem Satz mit ihnen z. B. inhaltsleere Buzzwords, wie 'streamlinen', so verwenden, dass auch der desinteressierte Bürger einem anerkennend zunickt. Jeder spürt: Wenn die Pipeline gebaut wurde, dann wird alles gut.\"\nauthor: Manuel Reif \ndate: 2025-04-14\nlang: de\ncategories: [R, mlr3, mlrpipelines]\ndraft: false \nhighlight-style: monokai\nimage: media/pancs.png\nexecute:\n    eval: true\n    message: false\n    echo: false\n    warning: false\n    freeze: true\nfilters:\n   - include-code-files\n---\n\n::: {.cell}\n\n:::\n\n\n\n<img src=\"media/pipes.jpg\" alt=\"True Piper\" style=\"float: right; width: 52%; margin-left: 20px; margin-bottom: 10px;\"/>\n\nPrinzipiell ist gegen Random Forests nichts einzuwenden, wenn man auf Retro-Modelle\naus den 90ern steht. Manche sagen auch \"bewährte Technik\". Allerdings muss\nman es sich auch erst einmal leisten können, die entsprechende Hardware anzuschaffen.\nDenn es ist das Eine, die Modelle zum Laufen zu bringen, aber das Andere, dass\nsie zu Lebzeiten auch fertig werden. Man freut sich ja, wenn der übergequollene \nArbeitsspeicher das Tuning nicht im Keim erstickt, weiß aber den schnellen Tod zu schätzen,\nwenn man gespannt auf Ergebnisse wartet, die nie geliefert werden.\n\nWogegen aber schon etwas einzuwenden ist, ist die sehr niedrige Meme Dichte im \nletzten Blog-Beitrag! Die Dichte verkam eher zum Vakuum.\nViele Menschen haben mich auf der Straße angesprochen, ob der überbordenden \nSeriosität, für die ich mich an dieser Stelle entschuldigen möchte. Dieser Beitrag\nsoll sich als Fels in der Brandung erheben, der sich der\n`stroke`-Betroffenheitswelle entgegenstemmt, die danach trachtete, \njeglichen humoristischen Ansatz im Keim zu ersticken.\n\nAlso, worum wird es im zweiten Teil gehen? \nWir schauen uns [mlr3pipelines](https://mlr3pipelines.mlr-org.com/) etwas \ndetaillierter an. Mit Pipelines\nkann man wunderbare Dinge machen, wie verschiedene Modelle parallel laufen zu lassen\nbzw. sie hintereinanderzuschalten (stacking).\n@fig-stacking1 zeigt uns gleich mal eine etwas komplexere Pipeline, wie sie auf\nunser `stroke` Klassifikationsproblem angewendet wurde.\nSchön bunt. Also was passiert hier?\n\n1. Im ersten Branch können wir uns nicht entscheiden, ob wir die Kategorie `Unknown`\nin der Variable `smoking status` imputieren sollen \n(nach dem Motto: irgendeinen wahren `smoking status` müssen die Leute ja haben)\noder ob wir einfach die Kategorie so lassen (nach dem Motto: Leute von denen man \nes nicht weiß, sind qualitativ eventuell anders als Leute, von denen man den Status weiß).\nDiese Frage eignet sich hervorragen, um an Teilnehmer:innen in einem Statistik \ngerichtet zu werden.\nNach 20 Minuten Diskussion, \nlernen alle, dass es nicht immer eine richtige Antwort gibt.\n2. Wir können uns nicht für ein Modell entscheiden. Daher trainieren wir mal mehrere\nModelle parallel und leiten die Ergebnisse dann an unseren Super Learner (`xgboost`) weiter.\nDer soll dann das beste draus machen. Und Achtung: `xgboost` ist nicht nur Super, \nsondern per Definition schon *extrem*.\n\n\n\n\n```{dot}\n//| fig-width: 6\n//| fig-height: 9\n//| label: fig-stacking1\n//| fig-cap: Unsere Stacking Pipeline\n\ndigraph pipeline {\n  rankdir=TB;\n  splines=ortho;\n  node [shape=box, style=filled, fontname=\"Helvetica\", fontsize=10];\n\n  robustify [label=\"Robustify Pipeline\", fillcolor=lightblue];\n\n  // Alle Knoten der vertikalen Kette in dieselbe Gruppe zwingen\n  branch    [label=\"Branch\\n(Unknown as Cat / Impute Unknown)\", fillcolor=steelblue, fixedsize=true, width=3.5];\n  imp_d_imp [label=\"Impute numeric\\nvariables\", fillcolor=orange, fixedsize=true, width=1.5, group=\"2\"]; // anderer Pfad\n  colapply  [label=\"Smoking\\nStatus:\\nUnknown as NA\", fillcolor=orange, fixedsize=true, width=1.5, group=\"1\"];\n  imp_f_uk  [label=\"Impute\\nSmoking\\nStatus\", fillcolor=orange, fixedsize=true, width=1.5, group=\"1\"];\n  imp_d_uk  [label=\"Impute\\nnum\\nvariables\", fillcolor=orange, fixedsize=true, width=1.5, group=\"1\"];\n  \n  unbranch [label=\"Merge branches\", fillcolor=steelblue, width=3.5];\n\n  // Basis-Learner als eigene Knoten in einem Cluster\n  subgraph cluster_base {\n    label=\"Base Learner\";\n    style=dashed;\n    nop [label=\"Original\\nDaten\", fillcolor=yellow];\n    rf  [label=\"RF\", fillcolor=yellow];\n    nb  [label=\"NB\", fillcolor=yellow];\n    knn [label=\"kNN\", fillcolor=yellow];\n    { rank=same; nop; rf; nb; knn; }\n  }\n  \n  base_union [label=\"Feature Union\\nbase learner\", shape=box, fillcolor=steelblue];\n  encode     [label=\"Encode\\n(One-Hot)\", fillcolor=lightblue];\n  xgboost    [label=\"Super-Learner\\nXGBoost\", fillcolor=red];\n\n  // --- Kanten ---\n  robustify -> branch;\n  branch -> imp_d_imp [tailport=s, headport=n];\n  branch -> colapply   [tailport=s, headport=n];\n  colapply   -> imp_f_uk [tailport=s, headport=n];\n  imp_f_uk   -> imp_d_uk [tailport=s, headport=n];\n  \n  imp_d_imp -> unbranch [tailport=s, headport=wn];\n  imp_d_uk  -> unbranch [tailport=s, headport=en];\n  \n  unbranch -> nop;\n  unbranch -> rf;\n  unbranch -> nb;\n  unbranch -> knn;\n  \n  nop  -> base_union;\n  rf   -> base_union;\n  nb   -> base_union;\n  knn  -> base_union;\n  \n  base_union -> encode;\n  encode     -> xgboost;\n}\n```\n\n\n\n\n\nIch wollte eigentlich recht ausführlich über die Ergebnisse berichten und \ndieses kompliziertere Modell mit dem einfachen Random Forest vergleichen.\nAber gut, wayne interessierts?\nAlso stürzen wir uns auf die Pipe!\n\n\n## Warum Pipelines?\n\n<img src=\"media/decide.jpg\" alt=\"True Piper\" style=\"float: right; width: 25%; margin-left: 20px; margin-bottom: 10px;\"/>\n\n\nJedem Anfang wohnt ein gewisser Zauber inne, sagen die einen. Die anderen sagen,\ndass man lieber die Finger von was Neuem lassen sollte, denn es kostet Zeit,\nNerven und am Ende bleibt man, mit einer hohen Wahrscheinlichkeit, doch bei dem,\nwas man vorher schon gekannt hat. Der bekannte Horror wird\nbevorzugt. Mir geht es mit neuen Packages meistens so, dass der Zauber ihnen nur so lange innewohnt,\nsolange ich mich oberflächlich mit dem Thema beschäftigt habe, Stichwort: Vorträge \nund YouTube-Videos.\n`mlr3` wirkt wie die Lösung aller Machine-Learning Probleme, bis zu dem Zeitpunkt,\nbei dem es sich dann selbst in die Schlange dieser Probleme einreiht.\nNach dem Motto: Bevor ich `mlr3` probiert habe, hatte ich ein Problem beim \nTunen meines Modells, jetzt habe ich zwei.\nTatsächlich (auch nachhaltig) positiv in diesem ganzen Prozess sind mir die `mlr3pipelines` aufgefallen.\nMit einer Pipeline kann man quasi ein Rezept erstellen, das beschreibt, was\nmit meinen Daten alles passieren soll, ohne dass man selbst kochen muss.\n\nDie Aufarbeitungsschritte werden nicht sofort umgesetzt, wie z. B. Variablen imputieren \noder standardisieren, sondern die Daten werden erst im Laufe des Tuning Prozesses, \nimmer wieder, aufbereitet. \nManchmal ist die Aufbereitung (wie bei uns) auch Teil des Modells.\nInsbesondere verhindert man, z. B. im Falle einer Crossvalidation (CV), dass Infos\nvon aus dem Trainingsdatensatz in den Test Datensatz \"leaken\".\nAuch hilfreich ist, dass man bestimmte Entscheidungen vielleicht nicht durch\n\"Expertenwissen\" treffen will^[Weil man vielleicht gar kein Experte ist!],\nsondern man kann auch einfach schauen was den besseren Fit ergibt.\nProbieren geht über studieren.\nAußerdem, kann man dann coole Grafiken machen.\n\n### Pipeline mit dem `stroke` Datensatz\n\n\nHier ist der Code, der die Pipeline beinhaltet die in @fig-stacking1 dargestellt \nist.\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Code: Stacking mit mlr3 (Achtung: Viel Code!)\"}\nlibrary(data.table)\nlibrary(magrittr)\nlibrary(mlr3)\nlibrary(mlr3tuning)\nlibrary(mlr3extralearners)\nlibrary(mlr3learners)\nlibrary(mlr3pipelines)\nlibrary(paradox)\nlibrary(bbotk)\nlibrary(mlr3mbo)\nlibrary(forcats)\nlibrary(future)\nlibrary(xgboost)\n\nplan(multisession)\n\n## Argumente uebernehmen\nargs <- commandArgs(trailingOnly = TRUE)\n\n# defaults\ndefault_evals    <- 10\ndefault_duration <- 1 * 60 * 60\n\nn_evals  <- ifelse(length(args) >= 1, as.integer(args[1]), default_evals)\nduration <- ifelse(length(args) >= 2, as.integer(args[2]), default_duration)\n\ncat(\"\\n -------------------------------------------- \\n\")\ncat(\"Tuning Stoppt nach:\\n\")\ncat(\"  Evals:\", n_evals, \"\\n\")\ncat(\"  Zeit in Sekunden:\", duration)\ncat(\"\\n -------------------------------------------- \\n\\n\")\n\nset.seed(42)\n\n# einlesen und modden\nd = fread(\"healthcare-dataset-stroke-data.csv\") %>% \n  .[, bmi := as.numeric(ifelse(bmi == \"N/A\", NA_character_, bmi))] %>% \n  .[, id := as.character(id)] %>% \n  .[gender != \"Other\",]\n\n# id muss ein character sein, sonst bekomme ich unten bei der rollenzuteilung einen error\n# denn ein \"name\" spalte muss character oder factor sein, aber nie integer - whyever\n\n\n#### TASK ######################################################################\n\n# es ist etwas kompliziert eine variable den feature status zu entziehen.\ntask_stroke = as_task_classif(d, target = \"stroke\")\ntask_stroke$col_roles$feature <- setdiff(task_stroke$col_roles$feature, \"id\")\ntask_stroke$col_roles$name <- \"id\"\ntask_stroke$set_col_roles(\"stroke\", c(\"target\",\"stratum\")) #<5>\n\nsplit = partition(task_stroke, ratio = 0.8) \n### learner --------------------------------------------------------------------\nlearner_rf = lrn(\"classif.ranger\", \n                 predict_type = \"prob\",\n                 respect.unordered.factors = \"partition\",\n                 num.trees = 3000,\n                 id = \"rf\") # mit id = \"rf\" kann ich bei ps dann die präambel kuerzer schreiben\n\n\nlearner_nb = lrn(\"classif.naive_bayes\", \n                 predict_type = \"prob\",\n                 id = \"nb\") \n\nlearner_knn = lrn(\"classif.kknn\", \n                  predict_type = \"prob\",\n                  id = \"knn\") \n\n# rf muss davor geschrieben werden, weil es sonst bei der pipe unklarheiten\n# bezueglich parameternamen gibt!\nparam_set = ps(\n  gabelung.selection = p_fct(levels = c(\"unknown_as_category\", \"impute_unknown\")),\n  cvnb.laplace = p_dbl(lower = 0, upper = 2),\n  cvnb.eps = p_dbl(lower = 1e-6, upper = 1e-2),\n  cvrf.mtry.ratio = p_dbl(0.4, 1),\n  cvrf.min.node.size = p_int(50, 1000),\n  super.eta = p_dbl(lower = 0.01, upper = 0.4),  # Lernrate von XGBoost\n  super.max_depth = p_int(lower = 3, upper = 11),  # Maximale Tiefe\n  super.nrounds = p_int(lower = 50, upper = 1000), # Anzahl der Boosting-Runden\n  cvknn.k = p_int(lower = 3, upper = 60)\n)\n\n### resampling -----------------------------------------------------------------\nresampling_CV5 = rsmp(\"cv\", folds = 5)\nmeasure_AUC    = msr(\"classif.auc\")\n\n### tuner ----------------------------------------------------------------------\ntuner_bayes = tnr(\"mbo\")\n\n### terminator -----------------------------------------------------------------\nterminator2 = trm(\"combo\",\n                  list(\n                    trm(\"evals\", n_evals = n_evals),\n                    trm(\"run_time\", secs = duration)\n                  )\n)\n\n################################################################################\n### pipeline -------------------------------------------------------------------\n################################################################################\n\ngabelung = po(\"branch\",\n              options = c(\"unknown_as_category\", \"impute_unknown\"), id = \"gabelung\")\n\nrobustifiy = pipeline_robustify(task = task_stroke, \n                                learner = learner_rf,\n                                character_action = \"factor!\",\n                                impute_missings = FALSE)\n\n#### keep unknown ==============================================================\n\n\npo_impute_f_uk <- po(\"imputelearner\", learner = lrn(\"classif.rpart\"), \n                     param_vals = list(\n                       affect_columns = selector_type(\"factor\")\n                     ), id = \"imp_f_uk\") # id notwendig weil sonst probleme bei robustify\n\npo_impute_d_uk <- po(\"imputelearner\", learner = lrn(\"regr.rpart\"), \n                     param_vals = list(\n                       affect_columns = selector_type(\"numeric\")\n                     ), id = \"imp_d_uk\")\n\n\n\ngraph_impute_unknown = po(\"colapply\",\n                          param_vals = list(\n                            applicator = function(x) {\n                              # x ist hier ein Vektor der Spalte\n                              x1 <- data.table::copy(x)\n                              x1[x == \"Unknown\"] <- NA_integer_\n                              res = forcats::fct_drop(x1)\n                              return(res)\n                            },\n                            affect_columns = selector_grep(\"smoking_status\")\n                          ), id = \"unknown_as_na\"\n) %>>%\n  po_impute_f_uk %>>%\n  po_impute_d_uk\n\n#### impute unknown ============================================================\n\npo_impute_d_imp <- po(\"imputelearner\", learner = lrn(\"regr.rpart\"), \n                      param_vals = list(\n                        affect_columns = selector_type(\"numeric\")\n                      ), id = \"imp_d\")\n\n#############\nsuper_learner = lrn(\"classif.rpart\", predict_type = \"prob\", id = \"super\")\n\n### stacking \n\nbase_learners = \n  gunion(list(\n    po(\"nop\", id = \"nop_original\"),\n    po(\"learner_cv\", learner = learner_rf, id = \"cvrf\"),\n    po(\"learner_cv\", learner = learner_nb, id = \"cvnb\"),\n    po(\"learner_cv\", learner = learner_knn, id = \"cvknn\")\n  )) %>>% po(\"featureunion\", id = \"base_learners\")\n\n#### COMBINED GRAPH ============================================================\n\ncombined_graph = robustifiy %>>% \n  gabelung %>>%\n  gunion(list(po_impute_d_imp, graph_impute_unknown)) %>>%\n  po(\"unbranch\", id = \"unbranch_main\") %>>%\n  base_learners %>>%\n  po(\"encode\", method = \"one-hot\", id = \"encode_super\") %>>% \n  po(\"learner\", learner = lrn(\"classif.xgboost\", predict_type = \"prob\", id = \"super\"))\n\n\n################################################################################\n\n### autotune -------------------------------------------------------------------\nat = AutoTuner$new(\n  learner = combined_graph,\n  resampling = resampling_CV5,\n  measure = measure_AUC,\n  search_space = param_set,\n  terminator = terminator2,\n  tuner = tuner_bayes\n)\n\nat$train(task_stroke, row_ids = split$train)\n\npred_res = at$predict(task_stroke, row_ids = split$test)\nauc_test = measure_AUC$score(pred_res)\n\nfull_res = list(at = at, \n                pred_res = pred_res, \n                auc_test = auc_test,\n                split = split)\n\nsaveRDS(full_res, \"output/at_stack2_splitted.rds\")  \n```\n:::\n\n\n\n\n\n\n\n## Was können Pipelines?\n\nDie Einzelteile einer Pipeline sind wie Mini-Modelle. \nAlso, man kann sie auch trainieren und wir bekommen ein etwas unübersichtliches, aber komplexes\nObjekt zurück. Wir nehmen jetzt mal den gekürzten Anfang unseres\ngestackten Modells, um uns dann mit den Pipes herumspielen zu können^[Was wir uns hier ansehen, hat weniger damit zu tun wie man Pipes tatsächlich einsetzt, sondern es geht mehr darum zu verstehen, was passiert!].\n\n\n\n\n::: {.cell}\n\n:::\n\n\n\n\n### Robustify\n\n<img src=\"media/robustify.jpg\" alt=\"Save the Algorithm\" style=\"float: right; width: 45%; margin-left: 20px; margin-bottom: 10px;\"/>\n\nWenn Modelle anfangen, Errors zu droppen, zieht es mich plötzlich ganz weit weg\nvom Computer. \n\n[Diese vorgefertigte Pipeline](https://mlr3pipelines.mlr-org.com/reference/mlr_graphs_robustify.html), \nsorgt dafür, dass es zu keinen bösen Überraschungen\nkommt! Aus meiner Sicht: Uneingeschränkte Empfehlung. Man erspart sich\nviele Fehlermeldungen! [Diesen Text zu lesen ist btw. auch sehr empfehlenswert!](https://mlr3book.mlr-org.com/chapters/chapter9/preprocessing.html)\nEs werden die Daten nur gerade so viel verändert, wie es für den `learner` \nunbedingt notwendig ist. Minimalistisch und zielführend.\n\n- \"factor!\" erzwingt, dass `character` Spalten zu `factor` umgewandelt werden.\nDie Pipeline würde das nicht machen, wenn es für den `learner` nicht notwendig wäre.\n- Es werden keine Missings imputiert. Das will ich dann später selbst machen.\n\n\n\n\n::: {.cell}\n\n:::\n\n\n\n\nWir sehen hier einen Vorher-/Nachher-Vergleich. \nZuerst sind noch einige `character`-Spalten enthalten, nachher, keine einzige mehr!\nWir sehen auch, dass die Spalten umsortiert wurden. Nun sind alle `factor`-Spalten\nin einem Block.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Vorher: \nsapply(task_stroke$data(), class)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n           stroke    Residence_type               age avg_glucose_level \n         \"factor\"       \"character\"         \"numeric\"         \"numeric\" \n              bmi      ever_married            gender     heart_disease \n        \"numeric\"       \"character\"       \"character\"         \"integer\" \n     hypertension    smoking_status         work_type \n        \"integer\"       \"character\"       \"character\" \n```\n\n\n:::\n\n```{.r .cell-code}\n# Anwenden der Robustify Pipe auf den Task \nres_rob = robustifiy$train(task_stroke)\n\n# Nachher:\nsapply(res_rob[[1]]$data(), class)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n           stroke    Residence_type      ever_married            gender \n         \"factor\"          \"factor\"          \"factor\"          \"factor\" \n   smoking_status         work_type               age avg_glucose_level \n         \"factor\"          \"factor\"         \"numeric\"         \"numeric\" \n              bmi     heart_disease      hypertension \n        \"numeric\"         \"integer\"         \"integer\" \n```\n\n\n:::\n:::\n\n\n\nMit der `plot` Methode lässt sich die Pipeline samt ihrer Elemente\nsogar interaktiv darstellen wie in @fig-robust zu sehen ist!\n\n\n\n\n::: {.cell}\n::: {#fig-robust .cell-output-display}\n\n```{=html}\n<div id=\"htmlwidget-d021586f9151eb615245\" style=\"width:50%;height:400px;\" class=\"visNetwork html-widget\"></div>\n<script type=\"application/json\" data-for=\"htmlwidget-d021586f9151eb615245\">{\"x\":{\"nodes\":{\"id\":[\"removeconstants_prerobustify\",\"char_to_fct\",\"fixfactors\",\"imputesample\",\"<INPUT>\",\"removeconstants_postrobustify\",\"<OUTPUT>\"],\"label\":[\"removeconstants_prerobustify\",\"char_to_fct\",\"fixfactors\",\"imputesample\",\"<INPUT>\",\"removeconstants_postrobustify\",\"<OUTPUT>\"],\"shape\":[\"box\",\"box\",\"box\",\"box\",\"database\",\"box\",\"ellipse\"],\"color\":[\"lightblue\",\"lightblue\",\"lightblue\",\"lightblue\",\"rgba(0,204,102,0.2)\",\"lightblue\",\"rgba(255,51,51,0.2)\"],\"value\":[1,1,1,1,0.8,1,0.8],\"title\":[\"<p>PipeOp: <b>removeconstants_prerobustify<\\/b> (trained)<br>values: <b>ratio=0, rel_tol=1e-08, abs_tol=1e-08, na_ignore=FALSE<\\/b><br>Input channels <b>name [train type, predict type]<\\/b>:<br>  input [Task,Task]<br>Output channels <b>name [train type, predict type]<\\/b>:<br>  output [Task,Task]<\\/p>\",\"<p>PipeOp: <b>char_to_fct<\\/b> (trained)<br>values: <b>applicator=<function>, affect_columns=<Selector><\\/b><br>Input channels <b>name [train type, predict type]<\\/b>:<br>  input [Task,Task]<br>Output channels <b>name [train type, predict type]<\\/b>:<br>  output [Task,Task]<\\/p>\",\"<p>PipeOp: <b>fixfactors<\\/b> (trained)<br>values: <b>droplevels=TRUE<\\/b><br>Input channels <b>name [train type, predict type]<\\/b>:<br>  input [Task,Task]<br>Output channels <b>name [train type, predict type]<\\/b>:<br>  output [Task,Task]<\\/p>\",\"<p>PipeOp: <b>imputesample<\\/b> (trained)<br>values: <b>affect_columns=<Selector><\\/b><br>Input channels <b>name [train type, predict type]<\\/b>:<br>  input [Task,Task]<br>Output channels <b>name [train type, predict type]<\\/b>:<br>  output [Task,Task]<\\/p>\",\"<p>Input:<br>Name: removeconstants_prerobustify.input<br>Train: Task<br>Predict: Task<\\/p>\",\"<p>PipeOp: <b>removeconstants_postrobustify<\\/b> (trained)<br>values: <b>ratio=0, rel_tol=1e-08, abs_tol=1e-08, na_ignore=TRUE<\\/b><br>Input channels <b>name [train type, predict type]<\\/b>:<br>  input [Task,Task]<br>Output channels <b>name [train type, predict type]<\\/b>:<br>  output [Task,Task]<\\/p>\",\"<p>Output:<br>Name: removeconstants_postrobustify.output<br>Train: Task<br>Predict: Task<\\/p>\"],\"x\":[0,0,0,0,0,0,0],\"y\":[-0.6666666666666667,-0.3333333333333334,0,0.3333333333333333,-1,0.6666666666666667,1]},\"edges\":{\"from\":[\"removeconstants_prerobustify\",\"char_to_fct\",\"fixfactors\",\"imputesample\",\"<INPUT>\",\"removeconstants_postrobustify\"],\"to\":[\"char_to_fct\",\"fixfactors\",\"imputesample\",\"removeconstants_postrobustify\",\"removeconstants_prerobustify\",\"<OUTPUT>\"],\"color\":[\"lightblue\",\"lightblue\",\"lightblue\",\"lightblue\",\"lightblue\",\"lightblue\"]},\"nodesToDataframe\":true,\"edgesToDataframe\":true,\"options\":{\"width\":\"100%\",\"height\":\"100%\",\"nodes\":{\"shape\":\"dot\",\"physics\":false},\"manipulation\":{\"enabled\":false},\"edges\":{\"arrows\":\"to\",\"smooth\":{\"enabled\":false,\"forceDirection\":\"vertical\"}},\"physics\":{\"stabilization\":false}},\"groups\":null,\"width\":\"50%\",\"height\":\"400px\",\"idselection\":{\"enabled\":false},\"byselection\":{\"enabled\":false},\"main\":null,\"submain\":null,\"footer\":null,\"background\":\"rgba(0, 0, 0, 0)\",\"igraphlayout\":{\"type\":\"full\"}},\"evals\":[],\"jsHooks\":[]}</script>\n```\n\n\nDie Robustify Pipeline mit ihren einzelnen Elementen.\n:::\n:::\n\n\n\n\n\n### Robustify - Mini Beispiel\n\nKonstanten machen Probleme, wenn man sie einfach so einer statistischen Methode\nzuführt. Die Methode erwartet Variablen. Eine Konstante hat diesen Namen\nnicht verdient, denn sie variiert ja per Definition nicht. Typischerweise\nwill man Konstanten loswerden, da sie nichts -- aber auch gar nichts --\nKonstruktives beitragen, um die Varianz von y zu erklären. Jetzt wäre es \nein leichtes, alle Konstanten zu eliminieren. Allerdings kann eine Variable,\ndie im Gesamtdatensatz noch ausreichend Variation zeigt, durch \ndie Gruppenbildung der Kreuzvalidierung zu einer Konstanten werden. Die\nAlarmglocken schrillen -- die Pipe kommt zur Hilfe.\nSchauen wir also mal, was passiert, wenn man eine\nKonstante im Datensatz hat.\n\nHier wird aber gleich mehrerlei ausprobiert, in dem kleinen Datensatz `dat_mini`.\nEs wird gleich *zweimal* `pipeline_robustify`\nmit unterschiedlichen Einstellungen ausgeführt.\n\n1. Hier wird erwähnt, dass explizit *nicht* imputiert werden soll\n2. Es soll imputiert werden und es sollen alle `character` Spalten `factor` werden,\negal, ob das notwendig ist oder nicht.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Simulation eines Mini Datensatzes\nset.seed(1653)\ndat_mini <- data.frame(\n    target = factor(sample(c(\"A\", \"B\", \"C\"), 20, replace = TRUE)),\n    feature1 = rnorm(20),\n    feature2 = sample(letters, 20, replace = TRUE),\n    constant_feature = 1  # <- konstante Spalte\n) %>% \n    data.table\n\ndat_mini[4:5, feature1 := NA_real_] # Missings erzeugen\n\n# Task erstellen\ntask_mini = as_task_classif(dat_mini, target = \"target\")\n\n# Robustify\nrobbi_mini1 = pipeline_robustify(task = task_mini, \n                                learner = learner_rf,\n                                impute_missings = FALSE\n                               )\n\nrobbi_mini2 = pipeline_robustify(task = task_mini, \n                                learner = learner_rf,\n                                character_action = \"factor!\",\n                                impute_missings = TRUE)\n\n# Graph trainieren\nrobbi_res1 = robbi_mini1$train(task_mini)\nrobbi_res2 = robbi_mini2$train(task_mini)\n```\n:::\n\n\n\nDas wirkt sich direkt auf die Daten aus.\n\n1. Hier sind noch die 2 Missings enthalten und `feature2` ist noch `character` \naber die Konstante ist weg!\n2. Hier ist ebenso die Konstante weg, Missings sind weg, `character` geändert und \neine neue Spalte hier, die anzeigt, wo ursprünglich Missings waren!\n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n   target   feature1 feature2\n   <fctr>      <num>   <char>\n1:      B -0.7315033        b\n2:      B  1.9773381        h\n3:      C  0.3296053        k\n4:      A         NA        j\n5:      B         NA        s\n6:      A -0.9334918        q\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   target feature2   feature1 missing_feature1\n   <fctr>   <fctr>      <num>           <fctr>\n1:      B        b -0.7315033          present\n2:      B        h  1.9773381          present\n3:      C        k  0.3296053          present\n4:      A        j  1.5194536          missing\n5:      B        s -1.1473332          missing\n6:      A        q -0.9334918          present\n```\n\n\n:::\n:::\n\n\n\n\n\n### Imputation\n\n<img src=\"media/imputation.jpg\" alt=\"Imputation\" style=\"float: right; width: 30%; margin-left: 20px; margin-bottom: 10px;\"/>\n\nWill man sich mit fehlenden Werten nicht zufriedengeben oder verwendet man\nobskure statistische Methoden, die mit fehlenden Werten nicht umgehen können,\nist es Zeit, sich etwas auszudenken. Der erste Impuls ist vielleicht, sofort zu imputieren,\ndenn die fehlenden Werte sind wie die von Datenkaries gefressenen Löcher in\nunserem, hoffentlich ansonsten gesunden, Datenzahn. Die sofortige Imputation ist \naber laut Beipackzettel nicht empfohlen und wird in Fachkreisen auch\n\"Imputatio Praecox\" genannt.\nDenn wer es sich leisten kann, und das sollte wirklich jeder, imputiert tunlichst\ninnerhalb der CV Samples, mit dem Ziel, keinerlei Informationen vom \nCV-Trainingssample an das CV-Testsample zu liefern. \nWer Style hat, imputiert also so spät wie möglich.\n\nDer Pipeline Operator `po` wird wie ein Modell trainiert.\nInteressant ist auch, dass in dem Fall für *alle* numerischen Variablen\nein Modell gemacht wird, egal ob es wirklich benötigt wird oder nicht.\nIn unserem Fall gibt es also Modelle für `age`, `avg_glucose_level` und `bmi`.\nWirklich angewendet würde es in der pipe nur für `bmi`. Dort dann automatisch.\nWir müssen die `predict` Methode verwenden, um die Werte wirklich zu imputieren.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npo_impute_d_imp <- po(\"imputelearner\", learner = lrn(\"regr.rpart\"), \n                      param_vals = list(\n                        affect_columns = selector_type(\"numeric\")\n                      ), id = \"imp_d\")\n\n\npo_impute_d_imp$train(res_rob)\ntsk_imputed = po_impute_d_imp$predict(res_rob)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nstate_imputer = po_impute_d_imp$state\ntrained_learners = state_imputer$model\n\nnames(trained_learners)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"age\"               \"avg_glucose_level\" \"bmi\"              \n```\n\n\n:::\n:::\n\n\n\nWir holen uns das Modell aus dem Objekt raus und können den Regression Tree, \nder als Methode gewählt wurde, plotten. @fig-imptree1 gibt Gelegenheit dazu,\ndie Splits, die der Baum gewählt hat, zu inspizieren. \nLeider dienen hier nur gerundete Werte \nder numerischen Einordnung. Die Autor:innen dieser schönen Funktion haben sich \nsehr viel Mühe gemacht, \nArgumente zu ersinnen, die eine mögliche Änderung des Rundungsverhaltens \ninsinnuieren, den Zahlendruck in der Grafik aber unangetastet lassen. \nMithilfe dieser Argumente lassen sich \nRundungen der verschiedensten Boxen feinabstimmen, um das, dem Eckigen abgeneigte, Auge nicht\nzu kränken. Ob dieser irreführenden Sackgassen, sackte ich in Resignation zusammen^[Das Argument `digits` verändert auch nichts an dieser mißlichen Lage!].\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_bmi = trained_learners[[\"bmi\"]]$model\n\nprp(model_bmi)\n```\n\n::: {.cell-output-display}\n![Der Imputations Tree für die Variable `bmi`](index_files/figure-html/fig-imptree1-1.png){#fig-imptree1 width=672}\n:::\n:::\n\n\n\nWir können auch nachvollziehen, ob und was imputiert wurde.\nStatt vieler Missings, sind nun Werte zu sehen, die wir dank der Rundungen \nin der vorigen Abbildung nicht wiedererkennen.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nindex_bmi_na = task_stroke$data()[,which(is.na(bmi))]\n\ncbind(tsk_imputed$output$data(rows = index_bmi_na, cols = \"bmi\") %>% head,\n      task_stroke$data(rows = index_bmi_na, cols = \"bmi\") %>% head)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n        bmi   bmi\n      <num> <num>\n1: 33.81869    NA\n2: 30.34060    NA\n3: 33.81869    NA\n4: 33.81869    NA\n5: 33.81869    NA\n6: 33.81869    NA\n```\n\n\n:::\n:::\n\n\n\n\nOk, Pipelines können noch viel mehr und es gäbe noch einiges herzuzeigen, \naber das kommt vielleicht in einem dritten Teil. Vielleicht auch nicht.\n\n\n<br>\n\n::: {style='text-align:center;'}\n\n\n\n{{< bi fire size=66px >}}\n\n\n\n\n:::\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"../../../site_libs/htmlwidgets-1.6.4/htmlwidgets.js\"></script>\n<link href=\"../../../site_libs/vis-9.1.0/vis-network.min.css\" rel=\"stylesheet\" />\n<script src=\"../../../site_libs/vis-9.1.0/vis-network.min.js\"></script>\n<script src=\"../../../site_libs/visNetwork-binding-2.1.2/visNetwork.js\"></script>\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}